<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Handjet:wght@800&display=swap" rel="stylesheet">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>SANS A.I</title>
    <style>
      body {
  margin: 0;
padding: 0;
display: flex;
justify-content: center;
align-items: center;
height: 100vh;
background: radial-gradient(circle, #000000 10%, #000000 60%, #006400);
background-size: 100% 100%;
overflow: hidden;font-family: 'Handjet', cursive;
}

#mic-button {
  width: 220px;
  height: 220px;
  border: none;
  border-radius: 50%;
  background: linear-gradient(135deg, #32cd32, #006400);
  color: #32cd32;
  font-size: 45px;
  font-weight: bold;
  cursor: pointer;
  display: flex;
  justify-content: center;
  align-items: center;
  box-shadow: 0 0 10px #00ff00, 0 0 30px #00ff00, 0 0 60px #00ff00;
  animation: glow 2s infinite;font-family: 'Handjet', cursive;
}

#mic-button {
  box-shadow: 0 0 20px #00ff00, 0 0 40px #00ff00, 0 0 80px #00ff00;
  animation: glow-hover 1.5s infinite;
}

@keyframes glow {
  0%, 100% {
    box-shadow: 0 0 10px #00ff00, 0 0 30px #00ff00, 0 0 60px #00ff00;
  }
  50% {
    box-shadow: 0 0 20px #32cd32, 0 0 40px #32cd32, 0 0 80px #32cd32;
  }
}

@keyframes glow-hover {
  0%, 100% {
    box-shadow: 0 0 20px #32cd32, 0 0 50px #32cd32, 0 0 100px #32cd32;
  }
  50% {
    box-shadow: 0 0 30px #00ff00, 0 0 60px #00ff00, 0 0 120px #00ff00;
  }
}

    </style>
  </head>
  <body>
    <button id="mic-button">PRESS</button>    <div id="container" style="display:none;">
            <video id="video" autoplay playsinline muted></video>
            <canvas id="canvas"></canvas>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    
<script>
  const API_KEY = "AIzaSyCsA5VjxUJAPzbstrF_bKfhPFY9zTYnVsM";
  const API_URL = `https://generativelanguage.googleapis.com/v1/models/gemini-1.5-pro:generateContent?key=${API_KEY}`;
  const micButton = document.getElementById("mic-button");
const container = document.getElementById("container");
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        let model;

        // Load the COCO-SSD model
        cocoSsd.load().then((loadedModel) => {
            model = loadedModel;
        });

  function getCurrentTime() {
    const now = new Date();
    const hours = now.getHours();
    const minutes = now.getMinutes();
    const ampm = hours >= 12 ? 'PM' : 'AM';
    const formattedHours = hours % 12 === 0 ? 12 : hours % 12;
    const formattedMinutes = minutes < 10 ? '0' + minutes : minutes;
    return `${formattedHours}:${formattedMinutes} ${ampm}`;
  }

  function getCurrentDate() {
    const now = new Date();
    const options = { weekday: 'long', year: 'numeric', month: 'long', day: 'numeric' };
    return now.toLocaleDateString('en-IN', options);
  }     async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: "environment" },
                audio: false
            });
            video.srcObject = stream;
            video.play();
        }

        // Perform object detection
        async function performDetection() {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            const predictions = await model.detect(canvas);
            if (predictions.length > 0) {
                const detectedObject = predictions[0].class; // First detected object
                console.log("Detected Object:", detectedObject);
                speak(detectedObject); // Speak the detected object
            } else {
                console.log("No object detected");
                speak("No object detected");
            }

            // Stop the video feed and hide the container after 5 seconds
            setTimeout(() => {
                const stream = video.srcObject;
                const tracks = stream.getTracks();
                tracks.forEach((track) => track.stop());
                video.srcObject = null;
                container.style.display = "none";
            }, 3000);
        }


  function speak(text) {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'en-IN';
    speechSynthesis.speak(utterance);
  }

  function searchOnGoogleMaps(locationName) {
    const searchQuery = locationName.trim();
    const response = `Searching on Google Maps for ${searchQuery}.`;
    window.open(`https://www.google.com/maps/search/${encodeURIComponent(searchQuery)}`, '_blank');
    speak(response);
  }

function getWeather(location) {
  fetch(`https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/${location}?unitGroup=metric&key=GBDFXBGMTTGEBT2X5M2CWRYSR&contentType=json`)
    .then(response => {
      if (!response.ok) {
        throw new Error('Network response was not ok');
      }
      return response.json();
    })
    .then(data => {
      const temp = data.currentConditions.temp;
      const response = `The temperature in ${location} is ${temp}°C`;
      console.log(`Fetched Weather Data for ${location}: Temperature is ${temp}°C`); // Logs temperature to console
      speak(response);
    })
    .catch(error => {
      console.error('Fetch error: ', error);
      speak('Unable to fetch temperature data.');
    });
}



  const recognizeSpeech = () => {
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = "en-IN";
    recognition.start();

    recognition.onresult = async (event) => {
      const question = event.results[0][0].transcript.toLowerCase().trim();
      console.log("User: " + question);

      let response = "I didn't understand that.";

      if (question.includes('wake up')) {
        const currentTime = new Date().getHours();
        if (currentTime >= 5 && currentTime < 12) {
          response = 'Good morning, sir.';
        } else if (currentTime >= 12 && currentTime < 17) {
          response = 'Good afternoon, sir.';
        } else if (currentTime >= 17 && currentTime < 21) {
          response = 'Good evening, sir.';
        } else {
          response = 'Good night, sir.';
        }
        speak(response);
      }else if (question === "scan") {
        container.style.display = "block";
        await setupCamera();
        video.addEventListener("click", performDetection);
} else if (question.startsWith('where is ')) {
        const locationName = question.substring('where is '.length).trim();
        searchOnGoogleMaps(locationName);
      } else if (question.startsWith(' weather of ') || question.startsWith('temperature of ')) {
        const location = question.substring(question.startsWith('weather of ') ? 'weather of '.length : 'temperature of '.length).trim();
        getWeather(location);
      } else if (question.includes('time is') || question.includes('what time is')) {
        response = `The current time is ${getCurrentTime()}.`;
        speak(response);
      } else if (question.includes('date') || question.includes('what date is')) {
        response = `Today's date is ${getCurrentDate()}.`;
        speak(response);
      } else if (question.includes('who made you')) {
        response = 'Mr.King made me.';
        speak(response);
      } else if (question.includes('who are you')) {
        response = 'i am Sans A.I mr.king assistant';
        speak(response);
      } else if (question.includes('how are you')) {
        response = 'i am fine';
        speak(response);
     
     }else if (question.toLowerCase().includes('open youtube')) {
        response = 'Opening youtube';
        window.open('https://www.youtube.com/', '_blank');
     } else if (question.toLowerCase().includes('from web')) {
  const searchQuery = question.replace('from web', '').trim(); // Remove the word "web" from the query
  response = `Searching the web for: ${searchQuery}`;
  window.open(`https://www.google.com/search?q=${encodeURIComponent(searchQuery)}`, '_blank');
  speak(response);
} else {
        response = await fetchResponse(question);
        speak(response);
      }

      console.log("AI: " + response);
    };

    recognition.onerror = (event) => {
      console.error("Speech recognition error:", event.error);
    };
  };

  const fetchResponse = async (query) => {
    const requestBody = {
      contents: [{
        role: "user",
        parts: [{ text: `Answer in a short, brief, and concise manner. Keep the answer under 30 words.  Question: ${query}` }]
      }],
    };

    try {
      const response = await fetch(API_URL, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(requestBody),
      });

      const data = await response.json();
      if (data && data.candidates) {
        let aiResponse = data.candidates[0].content.parts[0].text.trim();
        const words = aiResponse.split(' ');
        if (words.length > 30) {
          aiResponse = words.slice(0, 30).join(' ') + '...';
        }
        return aiResponse;
      } else {
        return "Sorry, I couldn't get that.";
      }
    } catch (error) {
      console.error("Error fetching response:", error);
      return "Oops, something went wrong.";
    }
  };

  micButton.addEventListener("click", recognizeSpeech);
</script>


  </body>
        </html>
        
